<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tensor Tiling Library: Introduction to the Tensor &amp; Tiling Library (TTL)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-theme.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="tensor_tiling_library_slim.png"/></td>
  <td id="projectalign">
   <div id="projectname">Tensor Tiling Library
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('md_v7F17Om__TTL_2doc_2tutorials_2introduction__to__ttl_2introduction__to__ttl.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Introduction to the Tensor &amp; Tiling Library (TTL)</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>CONTENTS: </h1>
<ul>
<li>Introduction to the Tensor &amp; Tiling Library (TTL)<ul>
<li>CONTENTS:</li>
<li>Introduction<ul>
<li>Example</li>
</ul>
</li>
<li>Background<ul>
<li>Tiling</li>
<li>Design Principles</li>
</ul>
</li>
<li>TTL Logical Tiling<ul>
<li>TTL\_create\_shape</li>
<li>TTL\_create\_overlap</li>
<li>TTL\_tile\_t</li>
<li>TTL\_tiler\_t</li>
</ul>
</li>
<li>TTL Physical Tensors<ul>
<li>TTL\_create\_layout</li>
<li>TTL\_\[const\]\_\[int,ext\]\_\[sub\]\_tensor\_t</li>
<li>TTL\_io\_tensors</li>
</ul>
</li>
<li>TTL Import and Export Transactions</li>
<li>TTL Pipelining Schemes<ul>
<li>Pipelining Iterations</li>
<li>Duplex Buffering</li>
<li>Double Buffering</li>
<li>Simplex Buffering</li>
</ul>
</li>
<li>Debugging</li>
<li>Tiling Code Examples<ul>
<li>Duplex Buffering Scheme</li>
<li>Double Buffering Scheme</li>
<li>Simplex Buffering Scheme</li>
<li>Overlapped Tiler</li>
<li>Parallelizing Tiling Loop</li>
<li>Manual Double Buffering: dxDMA</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>Introduction </h1>
<p>Code developed for devices that process data exceeding the capacity of their local memory must be partitioned into a series of stages, each of which processes data that fits in the available local memory. Even if local memory is large enough to accommodate all data in one single stage, it may be beneficial to partition code into multiple stages to better cope with the latency of copying data into and out of local memory. Such copying can be done asynchronously in OpenCL via <code>async_copy()</code> builtin functions, which we refer to as <code>import</code> and <code>export</code>.</p>
<p>Code for accelerators is often partitioned manually, resulting in code that is in general difficult and cumbersome to write, hard to read, share, optimize, and maintain.</p>
<p>The Tensor &amp; Tiling Library is designed to provide **transparent,<b> **modular</b>, and **extensible** **building-blocks** in **C**, to support developing code for local memory based accelerators, and in general where multi-dimensional tensors appear and are potentially tiled and pipelined.</p>
<h2>Example</h2>
<p>As a preliminary example, Tensor Tiling Library can be used as follows to tile a trivial a[i][j]=b[i][j]+1 kernel:</p>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define TILE_WIDTH 100</div>
<div class="line">#define TILE_HEIGHT 100</div>
<div class="line">#define TILE_SIZE (TILE_WIDTH * TILE_HEIGHT)</div>
<div class="line"> </div>
<div class="line">void compute(TTL_int_tensor_t t_in, TTL_int_tensor_t t_out) {</div>
<div class="line">   __local uchar *l_in = t_in.base;</div>
<div class="line">   __local uchar *l_out = t_out.base;</div>
<div class="line"> </div>
<div class="line">   for (unsigned int y = 0; y &lt; t_in.shape.height; y++) {</div>
<div class="line">     for (unsigned int x = 0; x &lt; t_in.shape.width; x++) {</div>
<div class="line">       int idx_out = y * t_out.layout.total_row_length + x;</div>
<div class="line">       int idx_in = y * t_in.layout.total_row_length + x;</div>
<div class="line">       l_out[idx_out] = l_in[idx_in] + 1;</div>
<div class="line">     }</div>
<div class="line">   }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void add_one(__global char *restrict input_image, __global char *restrict output_image,</div>
<div class="line">                      int image_width, int image_height, int image_stride)</div>
<div class="line">{</div>
<div class="line"> __local uchar l_in[TILE_SIZE];</div>
<div class="line"> __local uchar l_out[TILE_SIZE];</div>
<div class="line"> </div>
<div class="line"> // Regular tiling depends only on geometry aka logical tensors:</div>
<div class="line"> TTL_shape_t image_shape = TTL_create_shape(image_width, image_height);</div>
<div class="line"> TTL_shape_t tile_shape = TTL_create_shape(TILE_WIDTH, TILE_HEIGHT);</div>
<div class="line"> TTL_tiler_t tiler = TTL_create_tiler(image_shape, tile_shape);</div>
<div class="line"> </div>
<div class="line"> // Accessing memory depends on layout aka physical tensors, where strides are absolute:</div>
<div class="line"> TTL_layout_t external_layout = TTL_create_layout(image_stride);</div>
<div class="line"> </div>
<div class="line"> for (int tile_id = 0; tile_id &lt; TTL_number_of_tiles(tiler); ++tile_id) {</div>
<div class="line">   TTL_tile_t tile = TTL_get_tile(tile_id, tiler);</div>
<div class="line">   TTL_int_tensor_t import_to = TTL_create_int_tensor(l_in, tile);</div>
<div class="line">   TTL_int_tensor_t export_from = TTL_create_int_tensor(l_out, tile);</div>
<div class="line">   TTL_ext_tensor_t import_from = TTL_create_ext_tensor(input_image, tile, external_layout);</div>
<div class="line">   TTL_ext_tensor_t export_to = TTL_create_ext_tensor(output_image, tile, external_layout);</div>
<div class="line"> </div>
<div class="line">   TTL_blocking_import(import_to, import_from);</div>
<div class="line">   compute(import_to, export_from);</div>
<div class="line">   TTL_blocking_export(export_from, export_to);</div>
<div class="line"> }</div>
<div class="line">}</div>
</div><!-- fragment --><h1>Background </h1>
<h2>Tiling</h2>
<p>The **data** accessed by a function can be made to fit in local memory by **partitioning its control-flow** into stages, such that the data accessed by each stage fits in local memory. In all cases considered, this partitioning takes the form *Loop Tiling*, where an initial unfitting loop nest such as:</p>
<div class="fragment"><div class="line">for (int y = 0; y &lt; TooManyRows; ++y)</div>
<div class="line">  for (int x = 0; x &lt; TooManyColumns; ++x)</div>
<div class="line">    A[y * StrideA + x] = B[y * StrideB + x] + 1;</div>
</div><!-- fragment --><p>is strip-mined/blocked/tiled in (either or) both loops to produce:</p>
<div class="fragment"><div class="line">for (int y = 0; y &lt; TooManyRows; y += TileY)</div>
<div class="line">  for (int x = 0; x &lt; TooManyColumns; x += TileX) {</div>
<div class="line">    // Start of stage.</div>
<div class="line">    for (int yy = y; yy &lt; min(y + TileY , TooManyRows); ++yy)</div>
<div class="line">      for (int xx = x; xx &lt; min(x + TileX, TooManyColumns); ++xx)</div>
<div class="line">        A[yy * StrideA + xx] = B[yy * StrideB + xx] + 1;</div>
<div class="line">    // End of stage.</div>
<div class="line">  }</div>
</div><!-- fragment --><p>Loop tiling produces an outer-loop, in the above case a doubly-nested outer-loop, that iterates over stages or tiles. These outer loops could be represented as:</p>
<div class="fragment"><div class="line">for (int tile_id = 0; tile_id &lt; number_of_tiles; ++tile_id) {</div>
<div class="line">  // Derive y, x, and tile parameters from tile_id.</div>
<div class="line">}</div>
</div><!-- fragment --><p>Notice that both arrays A and B in the above example are tiled together. Arrays with multiple accesses of distinct offsets, such as in stencil access patterns, result in tiles that overlap. Arrays that are accessed with non-unit strides should be allocated increased memory accordingly along the x dimension - as if their element size has increased.</p>
<p>This transformation partitions or tiles the *Iteration Space* of a nested loop, thereby also partitioning or tiling the *Memory Space* of each array accessed in the loop. Tiling traditionally involves a single (usually 2D) tile size which applies to the outer-loop of a loop-nest in terms of iterations, and thereby to all tiled arrays of the loop in terms of elements. It can be extended to multiple loops by conceptually fusing them together. Each array however may require a distinct tile size due to its unique access pattern, and to be bumped by a unique stride along a distinct loop dimension.</p>
<p>Once a loop and the arrays it accesses have been tiled, the operations involved with copying the data of each tile can be double buffered and pipelined across loop iterations, thereby overlapping data communication with computation, and overlapping asynchronous imports and exports.</p>
<h2>Design Principles</h2>
<p>The Tensor Tiling Library is designed to be</p>
<ul>
<li><b>Transparent</b>: the types and functions of the library are all exposed and visible to the user; there are no hidden components. This helps clarify exactly what the library supports, and how.</li>
<li><b>Modular</b>: the library provides several constructs that can be used separately or in combination. This includes a construct for tensors, for regular tiling, a construct for importing and exporting single tiles, and a construct for pipelining a single or pairs of import/export transactions.</li>
<li><b>Extensible</b>: any part of the library can be copied and modified locally; new parts can be added locally to the library. Modification and additions regarded as generally useful should be considered for inclusion in the library.</li>
<li><b>Easy to use</b>: provides simple and easy to use patterns, all included in header-files only.</li>
</ul>
<p>A *tile* is considered to be a memory region that can be copied asynchronously. Therefore, a tile is in general a 3-dimensional *tensor* of elements, embedded within an enclosing memory layout.</p>
<p>In TTL tiles are defined with optional overlap in every dimension (see next section). For example, the following figure shows the tiling along x-dimension produced by a tiler with 2D space shape of (5, 250), 2D tile shape of (5, 5), and **overlap.width**=1, so that every pair of horizontally-adjacent tiles has one column of elements in common:</p>
<div class="image">
<img src="overlap.jpg" alt=""/>
</div>
    <p>The following figure shows all 15 tiles produced by a non-overlapping tiler with 2D space shape of {900, 800} and 2D tile shape of {200, 300}.</p>
<p>Note that tiles appearing last in each dimension are of smaller size - the remainder of dividing 900 by 200 and 800 by 300. Each tile has a unique ID from zero to **number_of_tiles**-1, following row-major or column-major order:</p>
<div class="image">
<img src="tiling_ttl.png" alt=""/>
</div>
    <p>The following sections describe the layers of API provided by TTL.</p>
<h1>TTL Logical Tiling </h1>
<p>The first layer of TTL deals with logical tiling of 3D shapes. The basic unit of these shapes - an "element" - is independent of its actual size or location in memory, hence the term "logical". The associated "physical" aspects of size and location in memory are dealt with separately.</p>
<h2>TTL_create_shape</h2>
<p><a class="el" href="structTTL__shape__t.html" title="Description of a Shape.">TTL_shape_t</a> defines the number of elements along each dimension in a 3D box:</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  TTL_dim_t width;  // Number of elements along dimension x.</div>
<div class="line">  TTL_dim_t height; // Number of rows along dimension y</div>
<div class="line">  TTL_dim_t depth;  // Number of planes along dimension z</div>
<div class="line">} TTL_shape_t;</div>
</div><!-- fragment --><p><a class="el" href="tensors_2TTL__types_8h.html#a9e6fdff7f83f529e9c4f2b13617eefb9" title="Create a description of a Shape.">TTL_create_shape()</a> APIs define shapes of desired dimensions, complementing remaining dimensions with '1's:</p>
<div class="fragment"><div class="line">TTL_shape_t TTL_create_shape(TTL_dim_t width);</div>
<div class="line">TTL_shape_t TTL_create_shape(TTL_dim_t width, TTL_dim_t height);</div>
<div class="line">TTL_shape_t TTL_create_shape(TTL_dim_t width, TTL_dim_t height, TTL_dim_t depth);</div>
</div><!-- fragment --><p>A "Big" 3D box can be partitioned into pairwise disjointed "Small" 3D boxes, simply by defining the two boxes as <a class="el" href="structTTL__shape__t.html" title="Description of a Shape.">TTL_shape_t</a>'s and using them to construct a <a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a>:</p>
<div class="fragment"><div class="line">TTL_tiler_t TTL_create_tiler(TTL_shape_t Big, TTL_shape_t Small);</div>
</div><!-- fragment --><p>This <a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a> can then be used to traverse all the parts of Big's partition (referred to as "tiles") each of size Small (or smaller), as explained below.</p>
<p>A Big 3D box can be partitioned into overlapping Small 3D boxes - where every pair of adjacent parts share a fixed number of elements along each dimension, using the following constructs:</p>
<h2>TTL_create_overlap</h2>
<p><a class="el" href="structTTL__overlap__t.html" title="Description of the overlap in 3D space of adjacent tiles.">TTL_overlap_t</a> defines the number of elements shared between two adjacent tiles along each dimension of a 3D box:</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  TTL_overlap_dim_t width;</div>
<div class="line">  TTL_overlap_dim_t height;</div>
<div class="line">  TTL_overlap_dim_t depth;</div>
<div class="line">} TTL_overlap_t;</div>
</div><!-- fragment --><p><a class="el" href="tensors_2TTL__types_8h.html#a78b3dfd89988803287fede4374a771c8" title="Create a 3D Description of a Tile overlap.">TTL_create_overlap()</a> APIs define the overlaps along the desired dimensions, complementing remaining dimensions with '0's:</p>
<div class="fragment"><div class="line">TTL_overlap_t TTL_create_overlap(TTL_overlap_dim_t width);</div>
<div class="line">TTL_overlap_t TTL_create_overlap(TTL_overlap_dim_t width, TTL_overlap_dim_t height);</div>
<div class="line">TTL_overlap_t TTL_create_overlap(TTL_overlap_dim_t width, TTL_overlap_dim_t height, TTL_overlap_dim_t depth);</div>
</div><!-- fragment --><p>An overlap can then be used together with Big and Small to create the desired overlapping tiler:</p>
<div class="fragment"><div class="line">TTL_tiler_t TTL_create_overlap_tiler(TTL_shape_t Big, TTL_shape_t Small, TTL_overlap_t Overlap);</div>
</div><!-- fragment --><h2><a class="el" href="structTTL__tile__t.html">TTL_tile_t</a></h2>
<p><a class="el" href="structTTL__tile__t.html">TTL_tile_t</a> defines the shape and position of each part in a partitioning produced by <a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a>:</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  TTL_shape_t shape;</div>
<div class="line">  TTL_shape_t offset; // In terms of number of elements</div>
<div class="line">} TTL_tile_t;</div>
</div><!-- fragment --><p>The offset defines where each tile "starts" and is therefore distinct across the tiles of a tiler, with a first tile typically starting at offset zero. The shapes are typically equal to the Small shape provided to the tiler, except for last tiles along each dimension which may be smaller. A tile having zero shape represents an empty or out-of-range tile.</p>
<h2><a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a></h2>
<p><a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a> provides the following APIs:</p>
<div class="fragment"><div class="line">int TTL_number_of_tiles(TTL_tiler_t t);       // Total number of tiles</div>
<div class="line">TTL_dim_t TTL_tiles_in_width(TTL_tiler_t t);  // Number of tiles in width</div>
<div class="line">TTL_dim_t TTL_tiles_in_height(TTL_tiler_t t); // Number of tiles in height</div>
<div class="line">TTL_dim_t TTL_tiles_in_depth(TTL_tiler_t t);  // Number of tiles in depth</div>
<div class="line">TTL_tile_t TTL_get_tile(int tile_id, TTL_tiler_t *t); // Return tile number tile_id, empty if tile_id is out of range</div>
<div class="line">int TTL_valid_tile_id(int tile_id, TTL_tiler_t t);    // Check if tile_id is in range</div>
</div><!-- fragment --><h1>TTL Physical Tensors </h1>
<p>The second layer of TTL deals with projecting or laying out logical tiles onto physical memory spaces.</p>
<p>Note that separating logical tiling from memory considerations facilitates reusing the same <a class="el" href="structTTL__tiler__t.html" title="TTL_tiler_t is the basic unit that describes how a tile is subdivided.">TTL_tiler_t</a> to tile distinct images (located in different memory addresses) with potentially distinct element sizes and memory alignments, provided they contain the same number and shape of elements to be tiled the same way.</p>
<h2>TTL_create_layout</h2>
<p>Each tile is embedded in global and local memories within some enclosing shape, e.g., to account for possible alignment padding. This embedding is referred to as *layout*, which specifies the spacing between the start of consecutive rows in units of elements, and spacing of the between start of consecutive planes in units of elements.</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">    TTL_dim_t row_spacing;    ///&lt; The distance between the start of consequtive rows in units of elements.</div>
<div class="line">    TTL_dim_t plane_spacing;  ///&lt; The distance between the start of consequtive planes in units of elements.</div>
<div class="line">} TTL_layout_t;</div>
</div><!-- fragment --><p><a class="el" href="TTL__tensors__common_8h.html#a7c5069ff7b3532a098b78635c5d574ee" title="Create a 1D Description of a Tensor layout in memory.">TTL_create_layout()</a> APIs define the layouts along the desired dimensions:</p>
<div class="fragment"><div class="line">TTL_layout_t TTL_create_layout();</div>
<div class="line">TTL_layout_t TTL_create_layout(TTL_dim_t total_row_length);</div>
<div class="line">TTL_layout_t TTL_create_layout(TTL_dim_t total_row_length, TTL_dim_t total_number_of_rows);</div>
</div><!-- fragment --><h2>TTL_ type family tensor_t</h2>
<p>TTL_[const]_[int/ext]_[sub]_tensor_t combine the logical dimensions of a tile along with its physical mapping to memory. The two constructs allow the creation of local [int] and global [ext] versions with a const attribute. The TTL_tensor_t structs contain all the information needed for issuing an import or export transaction, and for reading and writing to the tensor.</p>
<p>As well as usage for tiling the tensors should also be passed to compute functions. The type contains all the data needed to read from a tile that was imported and write to a tile before it is exported, except for the element type. An external tensor can also be passed to the kernel as it contains all data needed for tiling, importing and exporting.</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  [const] __[local/global] void *base;</div>
<div class="line">  TTL_dim_t elem_size;</div>
<div class="line">  TTL_layout_t layout;</div>
<div class="line">  TTL_shape_t shape;</div>
<div class="line">#if sub</div>
<div class="line">  struct {</div>
<div class="line">    TTL_shape_t shape;</div>
<div class="line">    TTL_offset_t sub_offset;</div>
<div class="line">    } origin;</div>
<div class="line">#endif</div>
<div class="line">} TTL_[const]_[ext/int]_[sub]_tensor_t ;</div>
</div><!-- fragment --><p>Tensors of the following types exit.</p>
<p><a class="el" href="TTL__int__tensors_8h.html#af55285c5c289c327379be3725265949a">TTL_int_tensor_t</a>; <br  />
 <a class="el" href="TTL__int__tensors_8h.html#a6f8d3bc7ab2c427d51a3addc5417bce0">TTL_const_int_tensor_t</a>; <br  />
 <a class="el" href="TTL__int__tensors_8h.html#a3b85de43f4885c4f5934a91c264b94cf">TTL_int_sub_tensor_t</a>; <br  />
 <a class="el" href="TTL__int__tensors_8h.html#afd5c161f2c63ba32b06df58efe26ecb7">TTL_const_int_sub_tensor_t</a>; <br  />
 <a class="el" href="TTL__ext__tensors_8h.html#ad75b1c0da822652819d4b8d0323db60d">TTL_ext_tensor_t</a>; <br  />
 <a class="el" href="TTL__ext__tensors_8h.html#a06baf9e44b059bf3571a491b880830fa">TTL_const_ext_tensor_t</a>; <br  />
 <a class="el" href="TTL__ext__tensors_8h.html#ab3d938ce68e12eafc7f9141554fdd33f">TTL_ext_sub_tensor_t</a>; <br  />
 <a class="el" href="TTL__ext__tensors_8h.html#a75688487ac2fdea7db309150d44414bf">TTL_const_ext_sub_tensor_t</a>;</p>
<div class="fragment"><div class="line">// Construct a buffer with default, packed layout, whose strides match the provided shape and element size w/o padding.</div>
<div class="line">// Element size is implicitly set to gentype size, where gentype represents any type amenable to sizeof, including but not restricted to OpenCL vector types, structs, but excluding void.</div>
<div class="line">TTL_int_tensor_t TTL_create_int_tensor(__local gentype *base, TTL_tile_t tile);</div>
<div class="line"> </div>
<div class="line">// Element size is implicitly set to gentype size, where gentype represents any type amenable to sizeof, including but not restricted to OpenCL vector types, structs, but excluding void.</div>
<div class="line">TTL_int_tensor_t TTL_create_int_tensor(__local gentype *base, TTL_tile_t tile, TTL_layout_t int_layout);</div>
<div class="line"> </div>
<div class="line">// Explicit layout and element size</div>
<div class="line">TTL_int_tensor_t TTL_create_int_tensor(__local gentype *base, TTL_tile_t tile, TTL_layout_t int_layout, int elem_size);</div>
<div class="line"> </div>
<div class="line">// Element size is implicitly set to gentype size, where gentype represents any type amenable to sizeof, including but not restricted to OpenCL vector types, structs, but excluding void.</div>
<div class="line">TTL_ext_tensor_t TTL_create_ext_tensor(__global gentype *base, TTL_tile_t tile, TTL_layout_t ext_layout);</div>
<div class="line"> </div>
<div class="line">// Explicit layout and element size</div>
<div class="line">TTL_ext_tensor_t TTL_create_ext_tensor(__global gentype *base, TTL_tile_t tile, TTL_layout_t ext_layout, int elem_size);</div>
<div class="line"> </div>
<div class="line">// Returns 1 if an internal tensor &#39;tensor&#39; is valid, i.e. has a non-empty shape. Otherwise, returns 0.</div>
<div class="line">// Useful when prolog/epilogs creates non-valid tensors.</div>
<div class="line">int TTL_valid_int_tensor(TTL_int_tensor_t tensor);</div>
</div><!-- fragment --><p>Explicit layouts and/or element size can be provided by overriding the default values. The API can also be extended with constructors for explicit sizes, if needed.</p>
<h2>TTL_io_tensors</h2>
<p>TTL_io_tensors_t holds two internal tensors ready for processing: imported_to as input tensor and to_export_from as output tensor:</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  TTL_int_tensor_t imported_to;</div>
<div class="line">  TTL_int_tensor_t to_export_from;</div>
<div class="line">} TTL_io_tensors_t;</div>
<div class="line"> </div>
<div class="line">// Returns true if tensors are valid.</div>
<div class="line">// Useful when prolog/epilogs creates non-valid tensors.</div>
<div class="line">int TTL_valid_tensors(TTL_io_tensors_t tensors);</div>
</div><!-- fragment --><h1>TTL Import and Export Transactions </h1>
<p>The third layer of TTL deals with transactions that copy tensors from global to local memory and back, referred to as import and export, respectively. These transactions are asynchronous and correspond to async_work_group_copy() builtin functions of OpenCL and their use of "event_t". Similar to OpenCL, in TTL one <a class="el" href="c_2TTL__types_8h.html#af7aafacf1b2d8b553b9b2dcd66925038" title="event_t is not supported, so provide a harmless placeholder">event_t</a> can serve multiple transactions, and it is possible to wait on multiple events. Unlike OpenCL, every import and export in TTL must be provided a non-null <a class="el" href="c_2TTL__types_8h.html#af7aafacf1b2d8b553b9b2dcd66925038" title="event_t is not supported, so provide a harmless placeholder">event_t</a>, which can be produced by <a class="el" href="opencl_2TTL__import__export_8h.html#ab52c0b665518000f2c402c5170a58ee2" title="Return an empty event of type TTL_event_t.">TTL_get_event()</a>.</p>
<div class="fragment"><div class="line">TTL_event_t TTL_get_event(); // Initialize an event.</div>
<div class="line"> </div>
<div class="line">// Import the data in external_tensor to internal_tensor.</div>
<div class="line">// The transaction is added to the event e.</div>
<div class="line">void TTL_import(TTL_int_tensor_t internal_tensor, TTL_ext_tensor_t external_tensor, TTL_event_t *e);</div>
<div class="line"> </div>
<div class="line">// Export the data in internal_tensor to external_tensor.</div>
<div class="line">// The transaction is added to the event e.</div>
<div class="line">void TTL_export(TTL_int_tensor_t internal_tensor, TTL_ext_tensor_t external_tensor, TTL_event_t *e);</div>
<div class="line"> </div>
<div class="line">void TTL_wait(int num_events, TTL_event_t *events); // Wait for first num_events in events array</div>
</div><!-- fragment --><p>TTL_blocking_import/export can be used to issue a blocking transaction, i.e., get an event, issue a transaction and immediately wait for its completion:</p>
<div class="fragment"><div class="line">void TTL_blocking_import(TTL_int_tensor_t internal_tensor, TTL_ext_tensor_t external_tensor);</div>
<div class="line">void TTL_blocking_export(TTL_int_tensor_t internal_tensor, TTL_ext_tensor_t external_tensor);</div>
</div><!-- fragment --><h1>TTL Pipelining Schemes </h1>
<p>The fourth layer of TTL deals with overlapping pairs of asynchronous import and export transactions and buffering pairs of internal tensors to facilitate pipelining of imports and exports.</p>
<p>TTL provides several schemes to help pipeline import and/or export transactions of tiles across a loop-over-tiles to overlap the transactions with computations and/or with themselves. Each scheme contains a struct, a defining function and a bumping function. The defining function initializes the struct and is placed before the loop to store data across loop iterations. The bumping function initializes and finalizes the transactions, returning TTL_tensor_t(s) to be used by their associated computation, and is placed inside the loop before the computations.</p>
<p>A <a class="el" href="TTL__int__tensors_8h.html#af55285c5c289c327379be3725265949a">TTL_int_tensor_t</a> returned by a bumping function that is associated with an import represents a tensor ready to be read-from, while a returned <a class="el" href="TTL__int__tensors_8h.html#af55285c5c289c327379be3725265949a">TTL_int_tensor_t</a> associated with an export is ready to be written-to and exported in the next invocation of the bumping function. The bumping functions receive a single tile, which may be the current or next tile, and record past tiles as needed.</p>
<p>Each scheme indicates how may prolog and/or epilog iterations it requires in order for its bumping function to be invoked sufficiently many times before and/or after their computation.</p>
<h2>Pipelining Iterations</h2>
<p>A scheme may require additional prolog and/or epilog iterations, which are represented and manipulated as follows:</p>
<div class="fragment"><div class="line">typedef struct {</div>
<div class="line">  int prolog; // Represents number of extra iterations which should be</div>
<div class="line">              // subtracted from the start of the loop-over-tiles.</div>
<div class="line">  int epilog; // Represents number of extra iterations which should be added to</div>
<div class="line">              // the end of the loop-over-tiles.</div>
<div class="line">} TTL_pipeline_iterations_t;</div>
<div class="line"> </div>
<div class="line">// Returns the number of prologs and epilogs required by a pipelining scheme.</div>
<div class="line">TTL_pipeline_iterations_t TTL_create_pipeline_iterations(void *scheme_base);</div>
<div class="line"> </div>
<div class="line">// Given existing pipeline_iterations struct and a pointer to a scheme, returns the required number of prologs and epilogs (performs maximum operation).</div>
<div class="line">TTL_pipeline_iterations_t TTL_join_pipeline_iterations(void *scheme_base, TTL_pipeline_iterations_t pipeline_iters);</div>
</div><!-- fragment --><h2>Duplex Buffering</h2>
<p>Given pair of blocking import and export that can execute concurrently, TTL_duplex_buffering issues them together and then waits on both to complete, hopefully executing them in parallel to each other. This scheme uses two internal buffers, one for the import and one for the export. Note that the export is pipelined to pair the import of the current tile with the export of previous tile.</p>
<p>The following table draws the pipelined actions performed in duplex buffering. It specifies which tile is processed in each iteration:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Action\Iteration   </th><th class="markdownTableHeadNone">#0   </th><th class="markdownTableHeadNone">#1   </th><th class="markdownTableHeadNone">#i (2:NumOfTiles-1)   </th><th class="markdownTableHeadNone">#NumOfTiles-    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Import</b>   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Wait Import</b>   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Compute</b>   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Export</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">i-1   </td><td class="markdownTableBodyNone">NumOfTiles-1    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>WaitExport</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">i-1   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td></tr>
</table>
<p>Notice the epilog (#NumOfTiles) which is an extra iteration.</p>
<p>Here are the interfaces to create and use the duplex buffering scheme:</p>
<div class="fragment"><div class="line">TTL_duplex_buffering_t TTL_create_duplex_buffering(__global void *ext_base_in, TTL_layout_t ext_layout_in, __local void *int_base_in, __global void *ext_base_out, TTL_layout_t ext_layout_out, __local void *int_base_out, TTL_event_t *event_in, TTL_event_t *event_out);</div>
<div class="line"> </div>
<div class="line">// Import current tile, export previous tile and wait for both transactions</div>
<div class="line">// Using the same tile dimensions for both importing and exporting, can also provide two distinct tiles.</div>
<div class="line">// Returns two internal buffers: one for input and one for output</div>
<div class="line">TTL_io_tensors_t TTL_step_buffering(TTL_duplex_buffering_t *scheme, TTL_tile_t tile);</div>
</div><!-- fragment --><p>For more infotmation see duplex buffering example.</p>
<h2>Double Buffering</h2>
<p>TTL_double_buffering pipelines a duplex import or export transaction using two internal buffers.</p>
<p>The following table draws the pipelined actions performed in double buffering. It specifies which tile is processed in each iteration:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Action\Iteration   </th><th class="markdownTableHeadNone">#-1   </th><th class="markdownTableHeadNone">#0   </th><th class="markdownTableHeadNone">#1   </th><th class="markdownTableHeadNone">#2   </th><th class="markdownTableHeadNone">#i (2:NumOfTiles-2)   </th><th class="markdownTableHeadNone">#NumOfTiles-1   </th><th class="markdownTableHeadNone">#NumOfTiles   </th><th class="markdownTableHeadNone">#NumOfTiles+1    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Wait Import</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Import</b>   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">i+1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>WaitExport</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">i-2   </td><td class="markdownTableBodyNone">NumOfTiles-3   </td><td class="markdownTableBodyNone">NumOfTiles-2   </td><td class="markdownTableBodyNone">NumOfTiles-1    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Export</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">i-1   </td><td class="markdownTableBodyNone">NumOfTiles-2   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Compute</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
</table>
<p>Notice the prolog (at iteration number -1) and the 2 epilogs (at iterations number NumOfTiles and NumOfTiles+1) which add in total 3 extra iterations.</p>
<p>Here are the interfaces to create and use the double buffering scheme:</p>
<div class="fragment"><div class="line">TTL_double_buffering_t TTL_create_import_double_buffering(</div>
<div class="line">          __local void *buff1, __local void *buff2, __global void *ext_base_in, TTL_layout_t ext_layout_in, TTL_event_t *event);</div>
<div class="line"> </div>
<div class="line">TTL_double_buffering_t TTL_create_export_double_buffering(</div>
<div class="line">          __local void *buff1, __local void *buff2, __global void *ext_base_out, TTL_layout_t ext_layout_out, TTL_event_t *event);</div>
<div class="line"> </div>
<div class="line">// Wait for last import and issue next import</div>
<div class="line">// Returns the waited tensor.</div>
<div class="line">TTL_int_tensor_t TTL_step_buffering(TTL_double_buffering_t *scheme, TTL_tile_t tile);</div>
<div class="line"> </div>
<div class="line">// Wait for last export and issue next export</div>
<div class="line">// Returns the waited tensor.</div>
<div class="line">TTL_int_tensor_t TTL_step_buffering(TTL_double_buffering_t *scheme, TTL_tile_t tile);</div>
</div><!-- fragment --><p>For more information see double buffering example</p>
<h2>Simplex Buffering</h2>
<p>TTL_simplex_buffering pipelines a pair of import and export transactions using three internal buffers, in rotation: each buffer interchangeably serves as input buffer and output buffer, such that in each iteration one buffer is used both to export then import and two buffers are used by compute for reading and writing.</p>
<p>With simplex buffering we're only waiting for previous iterations, so DMA transactions run mostly in parallel to computation, but serially with each other. Using the same buffer both for import and export is possible allowing us to overlap exporting from and importing to the same buffer.</p>
<p>The following table draws the pipelined actions performed in simplex buffering. It specifies which tile is processed in each iteration:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Action\Iteration   </th><th class="markdownTableHeadNone">#-1   </th><th class="markdownTableHeadNone">#0   </th><th class="markdownTableHeadNone">#1   </th><th class="markdownTableHeadNone">#2   </th><th class="markdownTableHeadNone">#i (2:NumOfTiles-2)   </th><th class="markdownTableHeadNone">#NumOfTiles-1   </th><th class="markdownTableHeadNone">#NumOfTiles   </th><th class="markdownTableHeadNone">#NumOfTiles+1    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>WaitExport</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">i-2   </td><td class="markdownTableBodyNone">NumOfTiles-3   </td><td class="markdownTableBodyNone">NumOfTiles-2   </td><td class="markdownTableBodyNone">NumOfTiles-1    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Export</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">i-1   </td><td class="markdownTableBodyNone">NumOfTiles-2   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Wait Import</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Import</b>   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">i+1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Compute</b>   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">i   </td><td class="markdownTableBodyNone">NumOfTiles-1   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
</table>
<p>Notice the prolog (at iteration number -1) and the 2 epilogs (at iterations number NumOfTiles and NumOfTiles+1) which add in total 3 extra iterations.</p>
<p>Here are the interfaces to create and use the simplex buffering scheme:</p>
<div class="fragment"><div class="line">TTL_simplex_buffering_t TTL_create_simplex_buffering(__global void *ext_base_in, __global void *ext_base_out, __local void *buff1, __local void *buff2, __local void *buff3, TTL_layout_t ext_layout_in, TTL_layout_t ext_layout_out, TTL_event_t *event_in, TTL_event_t *event_out);</div>
<div class="line"> </div>
<div class="line">/*</div>
<div class="line">1. Wait for previous import #i and export #i-2</div>
<div class="line">2. Trigger export #i-1, a local async fence or iab, and import #i+1</div>
<div class="line">* Both export #i-2 and import #i happen asynchronously back-to-back, effectively waiting for the latter import only.</div>
<div class="line">*/</div>
<div class="line">TTL_io_tensors_t TTL_step_buffering(TTL_simplex_buffering_t *scheme, TTL_tile_t tile);</div>
</div><!-- fragment --><p>For more information see simplex buffering example</p>
<p>See the Group Loop Bounds example for more information.</p>
<h1>Debugging </h1>
<p>TTL provides debugging information associated with tiling. Define TTL_DEBUG to turn on debugging:</p>
<div class="fragment"><div class="line">#define TTL_DEBUG</div>
<div class="line">#include &quot;TTL.h&quot;</div>
</div><!-- fragment --><p>Following is an example of what may be printed by TTL's debug mode:</p>
<div class="fragment"><div class="line">TTL_IMPORT: event=0x4088(channels mask=0x1) int_addr=0x108000 ext_base=0x4002f6580 ext_offset=(6144, 0, 0) shape=(512, 1, 1) ext_stride=(0, 0) int_stride=(0, 0) // line:62</div>
<div class="line">TTL_EXPORT: event=0x4089(channels mask=0x2) int_addr=0x118000 ext_base=0x400300b80 ext_offset=(5120, 0, 0) shape=(512, 1, 1) ext_stride=(0, 0) int_stride=(0, 0) // line:67</div>
<div class="line">TTL_WAIT: event=0x408a(channels mask=0x4) event=0x408b(channels mask=0x8) // line:69</div>
</div><!-- fragment --><h1>Tiling Code Examples </h1>
<p>This section provide code examples of kernels and tests that demonstrate the use of various TTL features.</p>
<h2>Duplex Buffering Scheme</h2>
<p>This example demonstrates how to use duplex buffering pipelining scheme.</p>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define MEMORY_SIZE (1 &lt;&lt; 14)</div>
<div class="line"> </div>
<div class="line">void compute(TTL_int_tensor_t tensor_in, TTL_int_tensor_t tensor_out) {</div>
<div class="line">  __local const uchar *restrict MEM0 l_in = tensor_in.base;</div>
<div class="line">  __local uchar *restrict MEM1 l_out = tensor_out.base;</div>
<div class="line">  int width = tensor_in.shape.width;</div>
<div class="line">  int height = tensor_in.shape.height;</div>
<div class="line">  int stride_in = tensor_in.layout.total_row_length;</div>
<div class="line">  int stride_out = tensor_out.layout.total_row_length;</div>
<div class="line"> </div>
<div class="line">  parrallel_for (y, height) {</div>
<div class="line">    parrallel_for (x, width) {</div>
<div class="line">      l_out[y * stride_out + x] =</div>
<div class="line">          l_in[y * stride_in + x] + 1;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">static inline void tile2tile_ref(__global uchar *restrict ext_base_in,</div>
<div class="line">                                 int external_stride_in,</div>
<div class="line">                                 __global uchar *restrict ext_base_out,</div>
<div class="line">                                 int external_stride_out, int width,</div>
<div class="line">                                 int height) {</div>
<div class="line">  for (unsigned y = 0; y &lt; height; ++y)</div>
<div class="line">      for (unsigned x = 0; x &lt; width; ++x)</div>
<div class="line">        ext_base_out[y * width + x] = ext_base_in[y * width + x] + 1;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void tile2tileCompute(__global uchar *restrict ext_base_in,</div>
<div class="line">                               int external_stride_in,</div>
<div class="line">                               __global uchar *restrict ext_base_out,</div>
<div class="line">                               int external_stride_out, int width, int height) {</div>
<div class="line">  local uchar l_in[MEMORY_SIZE];</div>
<div class="line">  local uchar l_out[MEMORY_SIZE];</div>
<div class="line"> </div>
<div class="line">  int tile_width = 40;</div>
<div class="line">  int tile_height = 48;</div>
<div class="line"> </div>
<div class="line">  // Logical tiling.</div>
<div class="line">  TTL_shape_t image_shape = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile_shape = TTL_create_shape(tile_width, tile_height);</div>
<div class="line">  TTL_tiler_t tiler = TTL_create_tiler(image_shape, tile_shape);</div>
<div class="line"> </div>
<div class="line">  // External layouts.</div>
<div class="line">  TTL_layout_t ext_layout_in = TTL_create_layout(external_stride_in);</div>
<div class="line">  TTL_layout_t ext_layout_out = TTL_create_layout(external_stride_out);</div>
<div class="line"> </div>
<div class="line">  /* sb_scheme must be defined outside, before the loop - because we</div>
<div class="line">    * &quot;time-shift&quot; the export to work on a recorded tile written to in</div>
<div class="line">    * previous iteration, instead of projecting it again using tile-1 - to</div>
<div class="line">    * optimize and avoid relying on previous tile being tile-1. */</div>
<div class="line">  TTL_event_t sb_e_in = TTL_get_event();</div>
<div class="line">  TTL_event_t sb_e_out = TTL_get_event();</div>
<div class="line">  TTL_duplex_buffering_t sb_scheme = TTL_create_duplex_buffering(</div>
<div class="line">      ext_base_in, ext_layout_in, l_in, ext_base_out, ext_layout_out, l_out,</div>
<div class="line">      &amp;sb_e_in, &amp;sb_e_out);</div>
<div class="line"> </div>
<div class="line">  TTL_pipeline_iterations_t pipeline_iters =</div>
<div class="line">      TTL_create_pipeline_iterations(&amp;sb_scheme);</div>
<div class="line">  for (int i = -pipeline_iters.prolog;</div>
<div class="line">        i &lt; TTL_number_of_tiles(tiler) + pipeline_iters.epilog; ++i) {</div>
<div class="line">    TTL_tile_t t = TTL_get_tile(i, tiler);</div>
<div class="line">    // Import current tile, export previous tile and wait for both</div>
<div class="line">    // transactions Using the same tile dimensions for both importing and</div>
<div class="line">    // exporting, can also provide two distinct tiles.</div>
<div class="line">    TTL_io_tensors_t tensors = TTL_step_buffering(&amp;sb_scheme, t);</div>
<div class="line">    if (TTL_valid_tensors(tensors))</div>
<div class="line">      compute(tensors.imported_to, tensors.to_export_from);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --> <h2>Double Buffering Scheme</h2>
<p>This example demonstrates how to use double buffering pipelining scheme.</p>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define MEMORY_SIZE (1 &lt;&lt; 14)</div>
<div class="line"> </div>
<div class="line">void compute(TTL_int_tensor_t tensor_in, TTL_int_tensor_t tensor_out) {</div>
<div class="line">  __local const uchar *restrict MEM0 l_in = tensor_in.base;</div>
<div class="line">  __local uchar *restrict MEM1 l_out = tensor_out.base;</div>
<div class="line">  int width = tensor_in.shape.width;</div>
<div class="line">  int height = tensor_in.shape.height;</div>
<div class="line">  int stride_in = tensor_in.layout.total_row_length;</div>
<div class="line">  int stride_out = tensor_out.layout.total_row_length;</div>
<div class="line"> </div>
<div class="line">  parrallel_for (y, height) {</div>
<div class="line">    parrallel_for (x, width) {</div>
<div class="line">      l_out[y * stride_out + x] =</div>
<div class="line">          l_in[y * stride_in + x] + 1;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">static inline void tile2tile_ref(__global uchar *restrict ext_base_in,</div>
<div class="line">                                 int external_stride_in,</div>
<div class="line">                                 __global uchar *restrict ext_base_out,</div>
<div class="line">                                 int external_stride_out, int width,</div>
<div class="line">                                 int height) {</div>
<div class="line">  for (unsigned y = 0; y &lt; height; ++y)</div>
<div class="line">      for (unsigned x = 0; x &lt; width; ++x)</div>
<div class="line">        ext_base_out[y * width + x] = ext_base_in[y * width + x] + 1;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void tile2tileCompute(__global uchar *restrict ext_base_in,</div>
<div class="line">                               int external_stride_in,</div>
<div class="line">                               __global uchar *restrict ext_base_out,</div>
<div class="line">                               int external_stride_out, int width, int height) {</div>
<div class="line">  local uchar l_in1[MEMORY_SIZE];</div>
<div class="line">  local uchar l_in2[MEMORY_SIZE];</div>
<div class="line">  local uchar l_out1[MEMORY_SIZE];</div>
<div class="line">  local uchar l_out2[MEMORY_SIZE];</div>
<div class="line"> </div>
<div class="line">  int tile_width = 128;</div>
<div class="line">  int tile_height = 88;</div>
<div class="line"> </div>
<div class="line">  // Logical tiling.</div>
<div class="line">  TTL_shape_t image_shape = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile_shape = TTL_create_shape(tile_width, tile_height);</div>
<div class="line">  TTL_tiler_t tiler = TTL_create_tiler(image_shape, tile_shape);</div>
<div class="line"> </div>
<div class="line">  // External layouts.</div>
<div class="line">  TTL_layout_t ext_layout_in = TTL_create_layout(external_stride_in);</div>
<div class="line">  TTL_layout_t ext_layout_out = TTL_create_layout(external_stride_out);</div>
<div class="line"> </div>
<div class="line">  // import_DB and export_DB need to be defined outside, before the loop, as they record the event to wait on</div>
<div class="line">  TTL_event_t import_DB_e = TTL_get_event();</div>
<div class="line">  TTL_event_t export_DB_e = TTL_get_event();</div>
<div class="line">  TTL_double_buffering_t import_DB = TTL_create_import_double_buffering(</div>
<div class="line">      l_in1, l_in2, ext_base_in, ext_layout_in, &amp;import_DB_e);</div>
<div class="line">  TTL_double_buffering_t export_DB = TTL_create_export_double_buffering(</div>
<div class="line">      l_out1, l_out2, ext_base_out, ext_layout_out, &amp;export_DB_e);</div>
<div class="line"> </div>
<div class="line">  TTL_pipeline_iterations_t pipeline_iters =</div>
<div class="line">      TTL_create_pipeline_iterations(&amp;import_DB);</div>
<div class="line">  pipeline_iters = TTL_join_pipeline_iterations(&amp;export_DB, pipeline_iters);</div>
<div class="line">  for (int i = -pipeline_iters.prolog;</div>
<div class="line">        i &lt; TTL_number_of_tiles(tiler) + pipeline_iters.epilog; ++i) {</div>
<div class="line">    TTL_tile_t t_next = TTL_get_tile(i+1, tiler);</div>
<div class="line">    // Wait for import #i and issue import #i+1</div>
<div class="line">    TTL_int_tensor_t imported_to = TTL_step_buffering(&amp;import_DB, t_next);</div>
<div class="line"> </div>
<div class="line">    TTL_tile_t t_curr = TTL_get_tile(i, tiler);</div>
<div class="line">    // Wait for export #i-2 and issue export #i-1</div>
<div class="line">    TTL_int_tensor_t exported_from = TTL_step_buffering(&amp;export_DB, t_curr);</div>
<div class="line"> </div>
<div class="line">    if (TTL_valid_int_tensor(imported_to))</div>
<div class="line">      compute(imported_to, exported_from);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2>Simplex Buffering Scheme</h2>
<p>This example demonstrates how to use double buffering pipelining scheme.</p>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define MEMORY_SIZE (1 &lt;&lt; 14)</div>
<div class="line"> </div>
<div class="line">void compute(TTL_int_tensor_t tensor_in, TTL_int_tensor_t tensor_out) {</div>
<div class="line">  __local const uchar *restrict MEM0 l_in = tensor_in.base;</div>
<div class="line">  __local uchar *restrict MEM1 l_out = tensor_out.base;</div>
<div class="line">  int width = tensor_in.shape.width;</div>
<div class="line">  int height = tensor_in.shape.height;</div>
<div class="line">  int stride_in = tensor_in.layout.total_row_length;</div>
<div class="line">  int stride_out = tensor_out.layout.total_row_length;</div>
<div class="line"> </div>
<div class="line">  parrallel_for (y, height) {</div>
<div class="line">    parrallel_for (x, width) {</div>
<div class="line">      l_out[y * stride_out + x] =</div>
<div class="line">          l_in[y * stride_in + x] + 1;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">static inline void tile2tile_ref(__global uchar *restrict ext_base_in,</div>
<div class="line">                                 int external_stride_in,</div>
<div class="line">                                 __global uchar *restrict ext_base_out,</div>
<div class="line">                                 int external_stride_out, int width,</div>
<div class="line">                                 int height) {</div>
<div class="line">  for (unsigned y = 0; y &lt; height; ++y)</div>
<div class="line">      for (unsigned x = 0; x &lt; width; ++x)</div>
<div class="line">        ext_base_out[y * width + x] = ext_base_in[y * width + x] + 1;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void tile2tileCompute(__global uchar *restrict ext_base_in,</div>
<div class="line">                               int external_stride_in,</div>
<div class="line">                               __global uchar *restrict ext_base_out,</div>
<div class="line">                               int external_stride_out, int width, int height) {</div>
<div class="line">  local uchar l_buff1[MEMORY_SIZE];</div>
<div class="line">  local uchar l_buff2[MEMORY_SIZE];</div>
<div class="line">  local uchar l_buff3[MEMORY_SIZE];</div>
<div class="line"> </div>
<div class="line">  int tile_width = 128;</div>
<div class="line">  int tile_height = 88;</div>
<div class="line"> </div>
<div class="line">  // Logical tiling.</div>
<div class="line">  TTL_shape_t image_shape = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile_shape = TTL_create_shape(tile_width, tile_height);</div>
<div class="line">  TTL_tiler_t tiler = TTL_create_tiler(image_shape, tile_shape);</div>
<div class="line"> </div>
<div class="line">  // External layouts.</div>
<div class="line">  TTL_layout_t ext_layout_in = TTL_create_layout(external_stride_in);</div>
<div class="line">  TTL_layout_t ext_layout_out = TTL_create_layout(external_stride_out);</div>
<div class="line"> </div>
<div class="line">  TTL_event_t tb_e_in = TTL_get_event();</div>
<div class="line">  TTL_event_t tb_e_out = TTL_get_event();</div>
<div class="line">  TTL_simplex_buffering_t tb_scheme = TTL_create_simplex_buffering(ext_base_in, ext_base_out, l_buff1, l_buff2, l_buff3, ext_layout_in, ext_layout_out, &amp;tb_e_in, &amp;tb_e_out);</div>
<div class="line"> </div>
<div class="line">  TTL_pipeline_iterations_t pipeline_iters =</div>
<div class="line">      TTL_create_pipeline_iterations(&amp;tb_scheme);</div>
<div class="line">  for (int i = -pipeline_iters.prolog;</div>
<div class="line">        i &lt; TTL_number_of_tiles(tiler) + pipeline_iters.epilog; ++i) {</div>
<div class="line">    TTL_tile_t next_tile = TTL_get_tile(i+1, tiler);</div>
<div class="line">    /*</div>
<div class="line">    1. Wait for previous import #i and export #i-2</div>
<div class="line">    2. Trigger export #i-1, a local async fence or iab, and import #i+1</div>
<div class="line">    * Both export #i-2 and import #i happen asynchronously back-to-back, effectively waiting for the latter import only.</div>
<div class="line">    */</div>
<div class="line">    // Using the same tile dimensions for both importing and exporting, can also provide two distinct tiles.</div>
<div class="line">    TTL_io_tensors_t tensors = TTL_step_buffering(&amp;tb_scheme, next_tile);</div>
<div class="line">    if (TTL_valid_tensors(tensors))</div>
<div class="line">      compute(tensors.imported_to, tensors.to_export_from);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2>Overlapped Tiler</h2>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define MEMORY_SIZE (1 &lt;&lt; 14)</div>
<div class="line">#define OVERLAP_WIDTH 7</div>
<div class="line">#define OVERLAP_HEIGHT 9</div>
<div class="line">#define TILE_WIDTH 40</div>
<div class="line">#define TILE_HEIGHT 30</div>
<div class="line"> </div>
<div class="line">void calc(TTL_int_tensor_t tensor_in, TTL_int_tensor_t tensor_out,</div>
<div class="line">          __local int *restrict avg) {</div>
<div class="line">  __local uchar *restrict MEM1 l_out = tensor_out.base;</div>
<div class="line">  __local const uchar *restrict MEM0 l_in = tensor_in.base;</div>
<div class="line">  __local int *restrict MEM2 l_avg = avg;</div>
<div class="line"> </div>
<div class="line">  int in_stride = tensor_in.layout.total_row_length;</div>
<div class="line">  int in_width = tensor_in.shape.width;</div>
<div class="line">  int in_height = tensor_in.shape.height;</div>
<div class="line">  int out_stride = tensor_out.layout.total_row_length;</div>
<div class="line">  int out_width = tensor_out.shape.width;</div>
<div class="line">  int out_height = tensor_out.shape.height;</div>
<div class="line"> </div>
<div class="line">  l_avg[0] = 0;</div>
<div class="line">  parrallel_for(y, in_height) {</div>
<div class="line">    parrallel_for(x, in_width) {</div>
<div class="line">      unsigned offset = y * in_stride + x;</div>
<div class="line">      l_avg[0] += (int)l_in[offset];</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  l_avg[0] /= (in_width * in_height);</div>
<div class="line"> </div>
<div class="line">  parrallel_for(y, out_height) {</div>
<div class="line">    parrallel_for(x, out_width) {</div>
<div class="line">      unsigned offset = y * out_stride+ x;</div>
<div class="line">      l_out[offset] = l_avg[0];</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void TTL_overlap(__global uchar *restrict inp,</div>
<div class="line">                          __global uchar *restrict out, int width, int height) {</div>
<div class="line">  __local uchar l_in[MEMORY_SIZE];</div>
<div class="line">  __local uchar l_out[MEMORY_SIZE];</div>
<div class="line">  __local int avg[1];</div>
<div class="line"> </div>
<div class="line">  // TTL setup</div>
<div class="line">  TTL_shape_t space_in = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile_shape_in = TTL_create_shape(TILE_WIDTH, TILE_HEIGHT);</div>
<div class="line">  TTL_overlap_t overlap = TTL_create_overlap(OVERLAP_WIDTH, OVERLAP_HEIGHT);</div>
<div class="line">  TTL_tiler_t tiler_in =</div>
<div class="line">      TTL_create_overlap_tiler(space_in, tile_shape_in, overlap);</div>
<div class="line">  TTL_layout_t layout_ext_in = TTL_create_layout(space_in.width);</div>
<div class="line"> </div>
<div class="line">  TTL_shape_t space_out =</div>
<div class="line">      TTL_create_shape(width - overlap.width, height - overlap.height);</div>
<div class="line">  TTL_shape_t tile_shape_out = TTL_create_shape(</div>
<div class="line">      TILE_WIDTH - overlap.width, TILE_HEIGHT - overlap.height);</div>
<div class="line">  TTL_tiler_t tiler_out = TTL_create_tiler(space_out, tile_shape_out);</div>
<div class="line">  TTL_layout_t layout_ext_out = TTL_create_layout(space_out.width);</div>
<div class="line"> </div>
<div class="line">  int num_tiles = TTL_number_of_tiles(tiler_in);</div>
<div class="line"> </div>
<div class="line">  for (int i = 0; i &lt; num_tiles; ++i) {</div>
<div class="line">    TTL_tile_t tile_in = TTL_get_tile(i, tiler_in);</div>
<div class="line">    TTL_int_tensor_t int_tensor_in = TTL_create_int_tensor(l_in, tile_in);</div>
<div class="line">    TTL_ext_tensor_t ext_tensor_in = TTL_create_ext_tensor(inp, tile_in, layout_ext_in);</div>
<div class="line">    TTL_blocking_import(int_tensor_in, ext_tensor_in);</div>
<div class="line"> </div>
<div class="line">    TTL_tile_t tile_out = TTL_get_tile(i, tiler_out);</div>
<div class="line">    TTL_int_tensor_t int_tensor_out = TTL_create_int_tensor(l_out, tile_out);</div>
<div class="line">    TTL_ext_tensor_t ext_tensor_out = TTL_create_ext_tensor(out, tile_out, layout_ext_out);</div>
<div class="line"> </div>
<div class="line">    if (TTL_valid_tile_id(i, tiler_in)) {</div>
<div class="line">      calc(int_tensor_in, int_tensor_out, avg);</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    TTL_blocking_export(int_tensor_out, ext_tensor_out);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2>Parallelizing Tiling Loop</h2>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">#define MEMORY_SIZE (1 &lt;&lt; 14)</div>
<div class="line"> </div>
<div class="line">void compute(TTL_int_tensor_t tensor_in, TTL_int_tensor_t tensor_out) {</div>
<div class="line">  __local const uchar *restrict MEM0 l_in = tensor_in.base;</div>
<div class="line">  __local uchar *restrict MEM1 l_out = tensor_out.base;</div>
<div class="line">  int width = tensor_in.shape.width;</div>
<div class="line">  int height = tensor_in.shape.height;</div>
<div class="line">  int stride_in = tensor_in.layout.total_row_length;</div>
<div class="line">  int stride_out = tensor_out.layout.total_row_length;</div>
<div class="line"> </div>
<div class="line">  parrallel_for(y, height) {</div>
<div class="line">    parrallel_for(x, width) {</div>
<div class="line">      l_out[y * stride_out + x] =</div>
<div class="line">          l_in[y * stride_in + x] + 1;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">__kernel void tile2tileCompute(__global uchar *restrict ext_base_in,</div>
<div class="line">                               int external_stride_in,</div>
<div class="line">                               __global uchar *restrict ext_base_out,</div>
<div class="line">                               int external_stride_out, int width, int height) {</div>
<div class="line">  local uchar l_in[MEMORY_SIZE];</div>
<div class="line">  local uchar l_out[MEMORY_SIZE];</div>
<div class="line"> </div>
<div class="line">  int tile_width = 48;</div>
<div class="line">  int tile_height = 40;</div>
<div class="line"> </div>
<div class="line">  // Logical tiling.</div>
<div class="line">  TTL_shape_t image_shape = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile_shape = TTL_create_shape(tile_width, tile_height);</div>
<div class="line">  TTL_tiler_t tiler = TTL_create_tiler(image_shape, tile_shape);</div>
<div class="line"> </div>
<div class="line">  // External layouts.</div>
<div class="line">  TTL_layout_t ext_layout_in = TTL_create_layout(external_stride_in);</div>
<div class="line">  TTL_layout_t ext_layout_out = TTL_create_layout(external_stride_out);</div>
<div class="line"> </div>
<div class="line">  /* sb_scheme must be defined outside, before the loop - because we</div>
<div class="line">    * &quot;time-shift&quot; the export to work on a recorded tile written to in</div>
<div class="line">    * previous iteration, instead of projecting it again using tile-1 - to</div>
<div class="line">    * optimize and avoid relying on previous tile being tile-1. */</div>
<div class="line">  TTL_event_t sb_e_in = TTL_get_event();</div>
<div class="line">  TTL_event_t sb_e_out = TTL_get_event();</div>
<div class="line">  TTL_single_buffering_t sb_scheme = TTL_create_single_buffering(</div>
<div class="line">      ext_base_in, ext_layout_in, l_in, ext_base_out, ext_layout_out, l_out,</div>
<div class="line">      &amp;sb_e_in, &amp;sb_e_out);</div>
<div class="line"> </div>
<div class="line">  TTL_pipeline_iterations_t pipeline_iters =</div>
<div class="line">      TTL_create_pipeline_iterations(&amp;sb_scheme);</div>
<div class="line">  TTL_loop_bounds_t bounds =</div>
<div class="line">      TTL_set_group_loop_bounds(&amp;tiler, pipeline_iters);</div>
<div class="line">  for (int i = bounds.lower; i &lt; bounds.upper; ++i) {</div>
<div class="line">    //printf(&quot;Iteration #%d, numoftiles: %d\n&quot;,i, TTL_number_of_tiles(tiler));</div>
<div class="line">    TTL_tile_t t = TTL_get_tile(i, tiler);</div>
<div class="line">    // Import current tile, export previous tile and wait for both</div>
<div class="line">    // transactions Using the same tile dimensions for both importing and</div>
<div class="line">    // exporting, can also provide two distinct tiles.</div>
<div class="line">    TTL_io_tensors_t tensors = TTL_step_buffering(&amp;sb_scheme, t);</div>
<div class="line">    if (TTL_valid_tensors(tensors))</div>
<div class="line">      compute(tensors.imported_to, tensors.to_export_from);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2>Manual Double Buffering: dxDMA</h2>
<p>This example shows how double buffering can be coded manually, i.e., w/o using TTL's scheme.</p>
<div class="fragment"><div class="line">#include &quot;TTL.h&quot;</div>
<div class="line"> </div>
<div class="line">__attribute__((noinline)) void</div>
<div class="line">calc_dx(__local char *restrict out_image,</div>
<div class="line">        __local const unsigned char *restrict input_image, int width,</div>
<div class="line">        int height) {</div>
<div class="line"> </div>
<div class="line">  parrallel_for(y, height) {</div>
<div class="line">    parrallel_for(xx, width - 2) {</div>
<div class="line">      unsigned x = x + 1;</div>
<div class="line">      int left = input_image[y * width + x - 1];</div>
<div class="line">      int right = input_image[y * width + x + 1];</div>
<div class="line">      out_image[y * width + x] = (right - left) &gt;&gt; 1;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">#define TILE_SZ (1 &lt;&lt; 14)</div>
<div class="line"> </div>
<div class="line">__kernel void TTL_dx(__global char *restrict dx_image,</div>
<div class="line">                     __global unsigned char *restrict input_image, int width,</div>
<div class="line">                     int height) {</div>
<div class="line">  __local unsigned char l_in1[TILE_SZ];</div>
<div class="line">  __local unsigned char l_in2[TILE_SZ];</div>
<div class="line">  __local char l_out1[TILE_SZ];</div>
<div class="line">  __local char l_out2[TILE_SZ];</div>
<div class="line"> </div>
<div class="line">  int tile_height = (1 &lt;&lt; 14) / width;</div>
<div class="line">  __local unsigned char *buffs_in[] = {l_in1, l_in2};</div>
<div class="line">  __local char *buffs_out[] = {l_out1, l_out2};</div>
<div class="line"> </div>
<div class="line">  // TTL setup</div>
<div class="line">  TTL_shape_t tensor = TTL_create_shape(width, height);</div>
<div class="line">  TTL_shape_t tile = TTL_create_shape(width, tile_height);</div>
<div class="line">  TTL_tiler_t tiler = TTL_create_tiler(tensor, tile);</div>
<div class="line">  TTL_layout_t external_layout = TTL_create_layout(width);</div>
<div class="line"> </div>
<div class="line">  TTL_event_t wait_in[2];</div>
<div class="line">  TTL_event_t wait_out[2];</div>
<div class="line"> </div>
<div class="line">  int buff_no = 0;</div>
<div class="line">  int num_tiles = TTL_number_of_tiles(tiler);</div>
<div class="line">  for (int i = -1; i &lt;= num_tiles; ++i) {</div>
<div class="line">    TTL_tile_t next_tile = TTL_get_tile(i + 1, tiler);</div>
<div class="line">    TTL_int_tensor_t int_tensor_in = TTL_create_int_tensor(buffs_in[1 - buff_no], next_tile);</div>
<div class="line">    TTL_ext_tensor_t ext_tensor_in = TTL_create_ext_tensor(input_image, next_tile, external_layout, sizeof(char));</div>
<div class="line">    wait_in[1 - buff_no] = TTL_get_event();</div>
<div class="line">    TTL_import(int_tensor_in, ext_tensor_in, &amp;wait_in[1 - buff_no]);</div>
<div class="line"> </div>
<div class="line">    TTL_tile_t prev_tile = TTL_get_tile(i - 1, tiler);</div>
<div class="line">    TTL_int_tensor_t int_tensor_out = TTL_create_int_tensor(buffs_out[1 - buff_no], prev_tile);</div>
<div class="line">    TTL_ext_tensor_t ext_tensor_out = TTL_create_ext_tensor(dx_image, prev_tile, external_layout);</div>
<div class="line">    wait_out[1 - buff_no] = TTL_get_event();</div>
<div class="line">    TTL_export(int_tensor_out, ext_tensor_out, &amp;wait_out[1 - buff_no]);</div>
<div class="line"> </div>
<div class="line">    TTL_wait(1, &amp;wait_in[buff_no]);</div>
<div class="line">    TTL_wait(1, &amp;wait_out[buff_no]);</div>
<div class="line"> </div>
<div class="line">    if (TTL_valid_tile_id(i, tiler)) {</div>
<div class="line">      TTL_tile_t curr_tile = TTL_get_tile(i, tiler);</div>
<div class="line">      calc_dx(buffs_out[buff_no], buffs_in[buff_no], width,</div>
<div class="line">              curr_tile.shape.height);</div>
<div class="line">    }</div>
<div class="line">    buff_no = 1 - buff_no;</div>
<div class="line">  }</div>
<div class="line">  TTL_wait(1, &amp;wait_out[buff_no]);</div>
<div class="line">}</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
